{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b56171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code adapted from the Confident Learning CIFAR-10 reproduce folder:\n",
    "# https://github.com/cgnorthcutt/confidentlearning-reproduce/blob/master/cifar10/cifar_create_label_errors.ipynb\n",
    "# Northcutt, C.; Jiang, L.; and Chuang, I. 2021. \n",
    "# Confident learning: Estimating uncertainty in dataset labels. \n",
    "# Journal of Artificial Intelligence Research.\n",
    "\n",
    "from cleanlab import noise_generation\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73601d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "dataset = \"cifar10\"\n",
    "sparsities = [0, 20, 40, 60]\n",
    "noise_rates = [0, 10, 20]\n",
    "###\n",
    "num_seeds = 10\n",
    "\n",
    "data_path = 'datasets/datasets/{}/{}/'.format(dataset, dataset)\n",
    "noisy_label_path = dataset + '_noisy_labels/'\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=data_path + 'train/',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]),\n",
    ")\n",
    "y = train_dataset.targets\n",
    "K = int(dataset[5:])\n",
    "\n",
    "for noise_amount in noise_rates:\n",
    "    for frac_zero_noise_rates in sparsities:\n",
    "        for seed in range(num_seeds):\n",
    "            if noise_amount < 1e-2 and frac_zero_noise_rates>0:\n",
    "                continue\n",
    "            print('noise_amount', round(noise_amount, 2), \n",
    "                  '| frac_zero_noise_rates', round(frac_zero_noise_rates, 2), \n",
    "                  '| seed', seed)\n",
    "            \n",
    "            # Generate class-conditional noise        \n",
    "            nm = noise_generation.generate_noise_matrix_from_trace(\n",
    "                K=K,\n",
    "                trace=int(K * (1 - noise_amount/100.)),\n",
    "                valid_noise_matrix=False,\n",
    "                frac_zero_noise_rates=frac_zero_noise_rates/100.,\n",
    "                seed=seed,\n",
    "            )\n",
    "\n",
    "            # noise matrix is valid if diagonal maximizes row and column\n",
    "            valid = all((nm.argmax(axis=0) == range(K)) & (nm.argmax(axis=1) == range(K)))\n",
    "            print('\\tValid:', valid)\n",
    "\n",
    "            # Create noisy labels\n",
    "            np.random.seed(seed=seed)\n",
    "            s = noise_generation.generate_noisy_labels(y, nm)\n",
    "            \n",
    "            # Check accuracy of s and y\n",
    "            print('\\tAccuracy of s and y:', sum(s==y)/len(s))\n",
    "\n",
    "            # Create map of filenames to noisy labels\n",
    "            d = dict(zip([i for i,j in train_dataset.imgs], [int(i) for i in s]))\n",
    "\n",
    "            # Store dictionary as json\n",
    "            wfn_base = '{}_noisy_labels__frac_zero_noise_rates__0.{}__noise_amount__0.{}'.format(\n",
    "                dataset,\n",
    "                '{0:0=2d}'.format(frac_zero_noise_rates),\n",
    "                '{0:0=2d}'.format(noise_amount),\n",
    "            )\n",
    "            \n",
    "            folder_path = noisy_label_path + wfn_base.replace('.','_') + '/seed_{}'.format(seed)\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            \n",
    "            wfn = os.path.join(folder_path, wfn_base)\n",
    "#             print('\\t', wfn)\n",
    "            # Store the dictionary        \n",
    "            with open(wfn + \".json\", 'w') as wf:\n",
    "                wf.write(json.dumps(d))\n",
    "\n",
    "            # Store the noise matrix as well\n",
    "            wfn_base = \"{}_noise_matrix\".format(dataset) + \"__\" + \"__\".join(wfn_base.split(\"__\")[1:])\n",
    "            wfn = os.path.join(folder_path, wfn_base)\n",
    "#             print('\\t', wfn)\n",
    "            with open(wfn + \".pickle\", 'wb') as wf:\n",
    "                pickle.dump(nm, wf, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b3099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
