{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cfc477",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "\n",
    "template = '\\\n",
    "--arch {arch} --seed {seed} --gpu {gpu} --workers 4 --save-loss \\\n",
    "--batch-size 128 --epochs 200 --learning-rate 0.1 \\\n",
    "--lr-scheduler CosineAnnealingLR --momentum 0.9 --weight-decay 0.0005 --lr-tmax 250 \\\n",
    "--train-labels {dataset}_noisy_labels/{base_folder}/{dataset}_noisy_labels__frac_zero_noise_rates__0.{sparsity}__noise_amount__0.{noise}.json \\\n",
    "datasets/datasets/{dataset}/{dataset}/ \\\n",
    "> {training_folder}/out_{arch}.log \\\n",
    "'\n",
    "\n",
    "folder_template = '{dataset}_noisy_labels__frac_zero_noise_rates__0_{sparsity}__noise_amount__0_{noise}/seed_{seed}'\n",
    "\n",
    "###\n",
    "dataset = 'cifar10'\n",
    "seeds = [0, 1, 2]\n",
    "sparsities = [0, 20, 40, 60] #[0, 20, 40, 60]\n",
    "noise_rates = [0, 10, 20] #[0, 10, 20]\n",
    "jobs_per_gpu = 1\n",
    "arch = 'resnet50'\n",
    "###\n",
    "\n",
    "\n",
    "num_jobs = 0\n",
    "all_tasks = []\n",
    "for seed in seeds:\n",
    "    for sparsity in sparsities:\n",
    "        for noise in noise_rates:\n",
    "            if noise < 1e-2 and sparsity>0:\n",
    "                continue\n",
    "            sparsity_str = '{0:0=2d}'.format(sparsity)\n",
    "            noise_str = '{0:0=2d}'.format(noise)\n",
    "            \n",
    "            base_folder = folder_template.format(dataset=dataset, sparsity=sparsity_str, noise=noise_str, seed=seed)\n",
    "            training_folder = '{}_training/'.format(dataset) + base_folder\n",
    "            print('mkdir -p', training_folder)\n",
    "            arg_str = template.format(\n",
    "                dataset=dataset,\n",
    "                seed=seed,\n",
    "                arch=arch,\n",
    "                gpu=0,\n",
    "                sparsity=sparsity_str,\n",
    "                noise=noise_str,\n",
    "                base_folder=base_folder,\n",
    "                training_folder=training_folder,\n",
    "            )\n",
    "            all_tasks.append(arg_str)\n",
    "            num_jobs += 1\n",
    "print('\\n'+'='*20, '\\nnum_jobs:',num_jobs, '\\nnum_tasks:',(num_jobs+jobs_per_gpu-1)//jobs_per_gpu)\n",
    "\n",
    "\n",
    "config = {}\n",
    "for i in range(len(all_tasks)):\n",
    "    task = all_tasks[i]\n",
    "    task_id = i // jobs_per_gpu\n",
    "    if task_id not in config:\n",
    "        config[task_id] = [task]\n",
    "    else:\n",
    "        config[task_id].append(task)\n",
    "print('\\ntask_assignment =', config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66326d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training with pruning\n",
    "\n",
    "\n",
    "template = '\\\n",
    "--arch {arch} --seed {seed} --gpu {gpu} --workers 4 --save-loss \\\n",
    "--prune-percent {prune_percent} --prune-schedule {prune_schedule} --prune-rm-schedule {prune_rm_schedule} \\\n",
    "--batch-size 128 --epochs 200 --learning-rate 0.1 \\\n",
    "--lr-scheduler CosineAnnealingLR --momentum 0.9 --weight-decay 0.0005 --lr-tmax 200 \\\n",
    "--train-labels {dataset}_noisy_labels/{base_folder}/{dataset}_noisy_labels__frac_zero_noise_rates__0.{sparsity}__noise_amount__0.{noise}.json \\\n",
    "datasets/datasets/{dataset}/{dataset}/ \\\n",
    "> {training_folder}/out_{arch}.log \\\n",
    "'\n",
    "\n",
    "folder_template = '{dataset}_noisy_labels__frac_zero_noise_rates__0_{sparsity}__noise_amount__0_{noise}/seed_{seed}'\n",
    "\n",
    "###\n",
    "dataset = 'cifar10'\n",
    "seeds = [0, 1, 2]\n",
    "sparsities = [0, 20, 40, 60] #[0, 20, 40, 60]\n",
    "noise_rates = [0, 10, 20] #[0, 10, 20]\n",
    "jobs_per_gpu = 1\n",
    "arch = 'resnet50'\n",
    "\n",
    "num_epochs = 200\n",
    "prune_period = 20\n",
    "prune_percent = 60\n",
    "prune_schedule = ' '.join([str(e) for e in range(\n",
    "    int(num_epochs*0.1), int(num_epochs*0.9), prune_period)])\n",
    "prune_rm_schedule = ' '.join([str(e) for e in range(\n",
    "    int(num_epochs*0.1)+int(prune_period//2), int(num_epochs*0.9)+1, prune_period)])\n",
    "###\n",
    "\n",
    "\n",
    "num_jobs = 0\n",
    "all_tasks = []\n",
    "for seed in seeds:\n",
    "    for sparsity in sparsities:\n",
    "        for noise in noise_rates:\n",
    "            if noise < 1e-2 and sparsity>0:\n",
    "                continue\n",
    "            sparsity_str = '{0:0=2d}'.format(sparsity)\n",
    "            noise_str = '{0:0=2d}'.format(noise)\n",
    "            \n",
    "            base_folder = folder_template.format(dataset=dataset, sparsity=sparsity_str, noise=noise_str, seed=seed)\n",
    "            training_folder = '{}_training_prune/'.format(dataset) + base_folder\n",
    "            print('mkdir -p', training_folder)\n",
    "            arg_str = template.format(\n",
    "                dataset=dataset,\n",
    "                seed=seed,\n",
    "                arch=arch,\n",
    "                gpu=0,\n",
    "                sparsity=sparsity_str,\n",
    "                noise=noise_str,\n",
    "                base_folder=base_folder,\n",
    "                training_folder=training_folder,\n",
    "                prune_percent=prune_percent,\n",
    "                prune_schedule=prune_schedule,\n",
    "                prune_rm_schedule=prune_rm_schedule,\n",
    "            )\n",
    "            all_tasks.append(arg_str)\n",
    "            num_jobs += 1\n",
    "print('\\n'+'='*20, '\\nnum_jobs:',num_jobs, '\\nnum_tasks:',(num_jobs+jobs_per_gpu-1)//jobs_per_gpu)\n",
    "\n",
    "\n",
    "config = {}\n",
    "for i in range(len(all_tasks)):\n",
    "    task = all_tasks[i]\n",
    "    task_id = i // jobs_per_gpu\n",
    "    if task_id not in config:\n",
    "        config[task_id] = [task]\n",
    "    else:\n",
    "        config[task_id].append(task)\n",
    "print('\\ntask_assignment =', config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7759f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4403f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train and combine cv\n",
    "\n",
    "\n",
    "template = '\\\n",
    "--arch {arch} --seed {seed} --gpu {gpu} --cvn {cvn} --cv {cv} --cv-seed 0 --workers 4 \\\n",
    "--batch-size 128 --epochs 200 --learning-rate 0.1 \\\n",
    "--lr-scheduler CosineAnnealingLR --momentum 0.9 --weight-decay 0.0005 --lr-tmax 200 \\\n",
    "--train-labels {dataset}_noisy_labels/{base_folder}/{dataset}_noisy_labels__frac_zero_noise_rates__0.{sparsity}__noise_amount__0.{noise}.json \\\n",
    "datasets/datasets/{dataset}/{dataset}/ \\\n",
    "> {training_folder}/out_{arch}__fold_{cv}.log \\\n",
    "'\n",
    "\n",
    "folder_template = '{dataset}_noisy_labels__frac_zero_noise_rates__0_{sparsity}__noise_amount__0_{noise}/seed_{seed}'\n",
    "\n",
    "combine_template = 'python {dataset}_train.py \\\n",
    "--arch {arch} --cvn {cvn} --cv-seed 0 --combine-folds \\\n",
    "--combine-source-path {training_folder}/ \\\n",
    "--combine-dest-path {cl_mask_folder}/ \\\n",
    "datasets/datasets/{dataset}/{dataset}/ \\\n",
    "'\n",
    "\n",
    "###\n",
    "dataset = 'cifar10'\n",
    "cvn = 4\n",
    "seeds = [0, 1, 2]\n",
    "sparsities = [0, 20, 40, 60] #[0, 20, 40, 60]\n",
    "noise_rates = [0, 10, 20] #[0, 10, 20]\n",
    "jobs_per_gpu = 1\n",
    "arch = 'resnet50'\n",
    "###\n",
    "\n",
    "\n",
    "num_jobs = 0\n",
    "all_tasks = []\n",
    "for seed in seeds:\n",
    "    for sparsity in sparsities:\n",
    "        for noise in noise_rates:\n",
    "            if noise < 1e-2 and sparsity>0:\n",
    "                continue\n",
    "            sparsity_str = '{0:0=2d}'.format(sparsity)\n",
    "            noise_str = '{0:0=2d}'.format(noise)\n",
    "            \n",
    "            base_folder = folder_template.format(dataset=dataset, sparsity=sparsity_str, noise=noise_str, seed=seed)\n",
    "            training_folder = '{}_training/'.format(dataset) + base_folder\n",
    "            print('mkdir -p', training_folder)\n",
    "            \n",
    "            for cv in range(cvn):\n",
    "                arg_str = template.format(\n",
    "                    dataset=dataset,\n",
    "                    seed=seed,\n",
    "                    arch=arch,\n",
    "                    gpu=0,\n",
    "                    cvn=cvn,\n",
    "                    cv=cv,\n",
    "                    sparsity=sparsity_str,\n",
    "                    noise=noise_str,\n",
    "                    base_folder=base_folder,\n",
    "                    training_folder=training_folder,\n",
    "                )\n",
    "                all_tasks.append(arg_str)\n",
    "                num_jobs += 1\n",
    "print('\\n'+'='*20, '\\nnum_jobs:',num_jobs, '\\nnum_tasks:',(num_jobs+jobs_per_gpu-1)//jobs_per_gpu)\n",
    "\n",
    "\n",
    "config = {}\n",
    "for i in range(len(all_tasks)):\n",
    "    task = all_tasks[i]\n",
    "    task_id = i // jobs_per_gpu\n",
    "    if task_id not in config:\n",
    "        config[task_id] = [task]\n",
    "    else:\n",
    "        config[task_id].append(task)\n",
    "print('\\ntask_assignment =', config)\n",
    "\n",
    "\n",
    "print('\\n'+'='*20+'\\n')\n",
    "for seed in seeds:\n",
    "    for sparsity in sparsities:\n",
    "        for noise in noise_rates:\n",
    "            if noise < 1e-2 and sparsity>0:\n",
    "                continue\n",
    "            sparsity_str = '{0:0=2d}'.format(sparsity)\n",
    "            noise_str = '{0:0=2d}'.format(noise)\n",
    "            \n",
    "            base_folder = folder_template.format(dataset=dataset, sparsity=sparsity_str, noise=noise_str, seed=seed)\n",
    "            training_folder = '{}_training/'.format(dataset) + base_folder\n",
    "            cl_mask_folder = '{}_mask_cl/{}'.format(dataset, base_folder)\n",
    "            print('mkdir -p', cl_mask_folder)\n",
    "            print(combine_template.format(\n",
    "                dataset=dataset,\n",
    "                arch=arch,\n",
    "                cvn=cvn,\n",
    "                training_folder=training_folder,\n",
    "                cl_mask_folder=cl_mask_folder,\n",
    "            ), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cde270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0141672",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# retraining\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "template = '\\\n",
    "--arch {arch} --seed {seed} --gpu {gpu} --workers 4 \\\n",
    "--batch-size 128 --epochs 200 --learning-rate 0.1 \\\n",
    "--lr-scheduler CosineAnnealingLR --momentum 0.9 --weight-decay 0.0005 --lr-tmax 200 \\\n",
    "--train-labels {dataset}_noisy_labels/{base_folder}/{dataset}_noisy_labels__frac_zero_noise_rates__0.{sparsity}__noise_amount__0.{noise}.json \\\n",
    "--dir-train-mask {mask_path} \\\n",
    "datasets/datasets/{dataset}/{dataset}/ \\\n",
    "> {training_folder}/out_{arch}.log \\\n",
    "'\n",
    "\n",
    "folder_template = '{dataset}_noisy_labels__frac_zero_noise_rates__0_{sparsity}__noise_amount__0_{noise}/seed_{seed}'\n",
    "s_template = '{dataset}_noisy_labels/{dataset}_noisy_labels__frac_zero_noise_rates__0_{sparsity}__noise_amount__0_{noise}/seed_{seed}/{dataset}_noisy_labels__frac_zero_noise_rates__0.{sparsity}__noise_amount__0.{noise}.json'\n",
    "mask_template = '{dataset}_mask{scl}/{base_folder}/{method}/model_{arch}_train_mask.npy'\n",
    "\n",
    "\n",
    "###\n",
    "dataset = 'cifar10'\n",
    "seeds = [0, 1, 2]\n",
    "sparsities = [0, 20, 40, 60] #[0, 20, 40, 60]\n",
    "noise_rates = [0, 10, 20] #[0, 10, 20]\n",
    "methods = ['kmeans', 'cl', 'no_clean'] # 'kmeans', 'cl', 'no_clean'\n",
    "jobs_per_gpu = 1\n",
    "arch = 'resnet50'\n",
    "###\n",
    "\n",
    "\n",
    "num_jobs = 0\n",
    "all_tasks = []\n",
    "for seed in seeds:\n",
    "    for sparsity in sparsities:\n",
    "        for noise in noise_rates:\n",
    "            if noise < 1e-2 and sparsity>0:\n",
    "                continue\n",
    "            sparsity_str = '{0:0=2d}'.format(sparsity)\n",
    "            noise_str = '{0:0=2d}'.format(noise)\n",
    "            base_folder = folder_template.format(dataset=dataset, sparsity=sparsity_str, noise=noise_str, seed=seed)\n",
    "            \n",
    "            for method in methods:\n",
    "                mask_path = mask_template.format(dataset=dataset, scl='', base_folder=base_folder, method=method, arch=arch)\n",
    "                training_folder = '{}_training_masked/{}/{}'.format(dataset, base_folder, method)\n",
    "                print('mkdir -p', training_folder)\n",
    "                \n",
    "                arg_str = template.format(\n",
    "                    dataset=dataset,\n",
    "                    seed=seed,\n",
    "                    arch=arch,\n",
    "                    gpu=0,\n",
    "                    sparsity=sparsity_str,\n",
    "                    noise=noise_str,\n",
    "                    base_folder=base_folder,\n",
    "                    mask_path=mask_path,\n",
    "                    training_folder=training_folder,\n",
    "                )\n",
    "                all_tasks.append(arg_str)\n",
    "                num_jobs += 1\n",
    "print('\\n'+'='*20, '\\nnum_jobs:',num_jobs, '\\nnum_tasks:',(num_jobs+jobs_per_gpu-1)//jobs_per_gpu)\n",
    "\n",
    "\n",
    "config = {}\n",
    "for i in range(len(all_tasks)):\n",
    "    task = all_tasks[i]\n",
    "    task_id = i // jobs_per_gpu\n",
    "    if task_id not in config:\n",
    "        config[task_id] = [task]\n",
    "    else:\n",
    "        config[task_id].append(task)\n",
    "print('\\ntask_assignment =', config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095de0e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# retraining with static model-pred labels\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "pred_template = '\\\n",
    "--make-train-label --label-outfile {label_outfile} \\\n",
    "--arch {arch} --gpu {gpu} --workers 4 --batch-size 256 \\\n",
    "--train-labels {label_path} \\\n",
    "--resume {model_path} \\\n",
    "--dir-train-mask {mask_path} \\\n",
    "datasets/datasets/{dataset}/{dataset}/ \\\n",
    "'\n",
    "template = '\\\n",
    "--arch {arch} --seed {seed} --gpu {gpu} --workers 4 \\\n",
    "--batch-size 128 --epochs 200 --learning-rate 0.1 \\\n",
    "--lr-scheduler CosineAnnealingLR --momentum 0.9 --weight-decay 0.0005 --lr-tmax 200 \\\n",
    "--train-labels {new_label_path} \\\n",
    "--dir-train-mask {mask_path} \\\n",
    "datasets/datasets/{dataset}/{dataset}/ \\\n",
    "> {training_folder}/out_{arch}.log \\\n",
    "'\n",
    "\n",
    "folder_template = '{dataset}_noisy_labels__frac_zero_noise_rates__0_{sparsity}__noise_amount__0_{noise}/seed_{seed}'\n",
    "s_template = '{dataset}_noisy_labels/{dataset}_noisy_labels__frac_zero_noise_rates__0_{sparsity}__noise_amount__0_{noise}/seed_{seed}/{dataset}_noisy_labels__frac_zero_noise_rates__0.{sparsity}__noise_amount__0.{noise}.json'\n",
    "mask_template = '{dataset}_mask{scl}/{base_folder}/{method}/model_{arch}_train_mask.npy'\n",
    "label_template = '{dataset}_noisy_labels/{base_folder}/{dataset}_noisy_labels__frac_zero_noise_rates__0.{sparsity}__noise_amount__0.{noise}.json'\n",
    "new_label_template = '{dataset}_mask{scl}/{base_folder}/{method}/cifar10_noisy_labels.json'\n",
    "model_template = '{dataset}_training/{base_folder}/model_{arch}_best.pth.tar'\n",
    "\n",
    "\n",
    "###\n",
    "dataset = 'cifar10'\n",
    "seeds = [0, 1, 2]\n",
    "sparsities = [0, 20, 40, 60] #[0, 20, 40, 60]\n",
    "noise_rates = [0, 10, 20] #[0, 10, 20]\n",
    "methods = ['kmeans_pred'] # 'kmeans_pred'\n",
    "jobs_per_gpu = 1\n",
    "arch = 'resnet50'\n",
    "###\n",
    "\n",
    "\n",
    "num_jobs = 0\n",
    "all_tasks = []\n",
    "for seed in seeds:\n",
    "    for sparsity in sparsities:\n",
    "        for noise in noise_rates:\n",
    "            if noise < 1e-2 and sparsity>0:\n",
    "                continue\n",
    "            sparsity_str = '{0:0=2d}'.format(sparsity)\n",
    "            noise_str = '{0:0=2d}'.format(noise)\n",
    "            base_folder = folder_template.format(dataset=dataset, sparsity=sparsity_str, noise=noise_str, seed=seed)\n",
    "            \n",
    "            for method in methods:\n",
    "                orig_method = method.split('_')[0]\n",
    "                orig_mask_path = mask_template.format(dataset=dataset, scl='', base_folder=base_folder, method=orig_method, arch=arch)\n",
    "                model_path = model_template.format(dataset=dataset, base_folder=base_folder, arch=arch)\n",
    "                label_path = label_template.format(dataset=dataset, base_folder=base_folder, sparsity=sparsity_str, noise=noise_str)\n",
    "                new_label_path = new_label_template.format(dataset=dataset, scl='', base_folder=base_folder, method=method)\n",
    "                \n",
    "                pred_str = pred_template.format(\n",
    "                    dataset=dataset,\n",
    "                    seed=seed,\n",
    "                    arch=arch,\n",
    "                    gpu=0,\n",
    "                    label_path=label_path,\n",
    "                    model_path=model_path,\n",
    "                    mask_path=orig_mask_path,\n",
    "                    label_outfile=new_label_path,\n",
    "                )\n",
    "                \n",
    "                training_folder = '{}_training_masked/{}/{}'.format(dataset, base_folder, method)\n",
    "                print('mkdir -p', training_folder)\n",
    "                no_clean_mask_path = mask_template.format(dataset=dataset, scl='', base_folder=base_folder, method='no_clean', arch=arch)\n",
    "                mask_path = mask_template.format(dataset=dataset, scl='', base_folder=base_folder, method=method, arch=arch)\n",
    "                print('mkdir -p', os.path.dirname(mask_path))\n",
    "                print('cp', no_clean_mask_path, mask_path)\n",
    "                \n",
    "                arg_str = template.format(\n",
    "                    dataset=dataset,\n",
    "                    seed=seed,\n",
    "                    arch=arch,\n",
    "                    gpu=0,\n",
    "                    new_label_path=new_label_path,\n",
    "                    mask_path=mask_path,\n",
    "                    training_folder=training_folder,\n",
    "                )\n",
    "                \n",
    "                all_tasks.append([pred_str, arg_str])\n",
    "                num_jobs += 1\n",
    "print('\\n'+'='*20, '\\nnum_jobs:',num_jobs, '\\nnum_tasks:',(num_jobs+jobs_per_gpu-1)//jobs_per_gpu)\n",
    "\n",
    "\n",
    "config = {}\n",
    "for i in range(len(all_tasks)):\n",
    "    task = all_tasks[i]\n",
    "    task_id = i // jobs_per_gpu\n",
    "    if task_id not in config:\n",
    "        config[task_id] = task\n",
    "    else:\n",
    "        config[task_id].append(task)\n",
    "print('\\ntask_assignment =', config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59edc7b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# retraining with dynamic model-pred labels\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "template = '\\\n",
    "--dynamic-train-label --dynamic-frac-start 0.5  --dynamic-frac-end 0.9 \\\n",
    "--arch {arch} --seed {seed} --gpu {gpu} --workers 4 \\\n",
    "--batch-size 128 --epochs 200 --learning-rate 0.1 \\\n",
    "--lr-scheduler CosineAnnealingLR --momentum 0.9 --weight-decay 0.0005 --lr-tmax 200 \\\n",
    "--train-labels {dataset}_noisy_labels/{base_folder}/{dataset}_noisy_labels__frac_zero_noise_rates__0.{sparsity}__noise_amount__0.{noise}.json \\\n",
    "--dir-train-mask {mask_path} \\\n",
    "datasets/datasets/{dataset}/{dataset}/ \\\n",
    "> {training_folder}/out_{arch}.log \\\n",
    "'\n",
    "\n",
    "folder_template = '{dataset}_noisy_labels__frac_zero_noise_rates__0_{sparsity}__noise_amount__0_{noise}/seed_{seed}'\n",
    "s_template = '{dataset}_noisy_labels/{dataset}_noisy_labels__frac_zero_noise_rates__0_{sparsity}__noise_amount__0_{noise}/seed_{seed}/{dataset}_noisy_labels__frac_zero_noise_rates__0.{sparsity}__noise_amount__0.{noise}.json'\n",
    "mask_template = '{dataset}_mask{scl}/{base_folder}/{method}/model_{arch}_train_mask.npy'\n",
    "\n",
    "\n",
    "###\n",
    "dataset = 'cifar10'\n",
    "seeds = [0, 1, 2]\n",
    "sparsities = [0, 20, 40, 60] #[0, 20, 40, 60]\n",
    "noise_rates = [0, 10, 20] #[0, 10, 20]\n",
    "methods = ['kmeans_pred_dyn'] # 'kmeans_pred_dyn'\n",
    "jobs_per_gpu = 1\n",
    "arch = 'resnet50'\n",
    "###\n",
    "\n",
    "\n",
    "num_jobs = 0\n",
    "all_tasks = []\n",
    "for seed in seeds:\n",
    "    for sparsity in sparsities:\n",
    "        for noise in noise_rates:\n",
    "            if noise < 1e-2 and sparsity>0:\n",
    "                continue\n",
    "            sparsity_str = '{0:0=2d}'.format(sparsity)\n",
    "            noise_str = '{0:0=2d}'.format(noise)\n",
    "            base_folder = folder_template.format(dataset=dataset, sparsity=sparsity_str, noise=noise_str, seed=seed)\n",
    "            \n",
    "            for method in methods:\n",
    "                orig_method = method.split('_')[0]\n",
    "                orig_mask_path = mask_template.format(dataset=dataset, scl='', base_folder=base_folder, method=orig_method, arch=arch)\n",
    "                mask_path = mask_template.format(dataset=dataset, scl='', base_folder=base_folder, method=method, arch=arch)\n",
    "                print('mkdir -p', os.path.dirname(mask_path))\n",
    "                print('cp', orig_mask_path, mask_path)\n",
    "                \n",
    "                training_folder = '{}_training_masked/{}/{}'.format(dataset, base_folder, method)\n",
    "                print('mkdir -p', training_folder)\n",
    "                \n",
    "                arg_str = template.format(\n",
    "                    dataset=dataset,\n",
    "                    seed=seed,\n",
    "                    arch=arch,\n",
    "                    gpu=0,\n",
    "                    sparsity=sparsity_str,\n",
    "                    noise=noise_str,\n",
    "                    base_folder=base_folder,\n",
    "                    mask_path=mask_path,\n",
    "                    training_folder=training_folder,\n",
    "                )\n",
    "                all_tasks.append(arg_str)\n",
    "                num_jobs += 1\n",
    "print('\\n'+'='*20, '\\nnum_jobs:',num_jobs, '\\nnum_tasks:',(num_jobs+jobs_per_gpu-1)//jobs_per_gpu)\n",
    "\n",
    "\n",
    "config = {}\n",
    "for i in range(len(all_tasks)):\n",
    "    task = all_tasks[i]\n",
    "    task_id = i // jobs_per_gpu\n",
    "    if task_id not in config:\n",
    "        config[task_id] = [task]\n",
    "    else:\n",
    "        config[task_id].append(task)\n",
    "print('\\ntask_assignment =', config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50494a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
