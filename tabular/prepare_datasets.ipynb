{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from cleanlab import noise_generation\n",
    "\n",
    "from utils import *\n",
    "pd.options.mode.chained_assignment = None # None / 'warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "noise_amount = 0.2\n",
    "###\n",
    "frac_zero_noise_rates = 0\n",
    "seeds = list(range(10))\n",
    "\n",
    "def _helper():\n",
    "    for seed in seeds:\n",
    "        df_train_scaled, df_test_scaled, continuous_features, categorical_features = get_data(seed)\n",
    "        \n",
    "        # generate symmetric noise\n",
    "        np.random.seed(seed=seed)\n",
    "        num_class = len(np.unique(df_train_scaled[\"Target\"]))\n",
    "        nm = np.ones((num_class, num_class)) * noise_amount/(num_class-1)\n",
    "        np.fill_diagonal(nm, 1-noise_amount)\n",
    "        y_train_clean_arr = copy.deepcopy(df_train_scaled[\"Target\"].to_numpy())\n",
    "        s = noise_generation.generate_noisy_labels(y_train_clean_arr, nm)\n",
    "        df_train_scaled[\"Target\"] = s\n",
    "        \n",
    "        # save processed train and test data\n",
    "        folderpath = os.getcwd()+'/datasets/{}/seed_{}/data'.format(dataset, seed)\n",
    "        save_data(folderpath, df_train_scaled, df_test_scaled, continuous_features, categorical_features, y_train_clean_arr=y_train_clean_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b119533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30579950",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Cardiotocography'\n",
    "\n",
    "### read dataset\n",
    "# source: http://archive.ics.uci.edu/ml/datasets/Cardiotocography \n",
    "datapath = 'data_raw/Cardiotocography/CTG.xls'\n",
    "df = pd.read_excel(datapath, 'Data')\n",
    "\n",
    "df.drop('DL.1', axis=1, inplace=True)\n",
    "df.drop('DS.1', axis=1, inplace=True)\n",
    "df.drop('DP.1', axis=1, inplace=True)\n",
    "df.drop('b', axis=1, inplace=True)\n",
    "df.drop('e', axis=1, inplace=True)\n",
    "df.drop('AC', axis=1, inplace=True)\n",
    "df.drop('FM', axis=1, inplace=True)\n",
    "df.drop('UC', axis=1, inplace=True)\n",
    "\n",
    "### remove empty columns\n",
    "missing_features = df.isnull().sum()\n",
    "empty_columns = missing_features[missing_features>=200].index\n",
    "df.drop(empty_columns, axis=1, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "### preprocessing columns\n",
    "# assign the column name of the target feature as \"Target\"\n",
    "df.rename(columns={\"NSP\":\"Target\"}, inplace=True)\n",
    "# make sure the label ranges from 0 to (num_class-1)\n",
    "# Targets = Normal=0; Suspect=1; Pathologic=2\n",
    "df[\"Target\"] = df[\"Target\"].replace({1:0})\n",
    "df[\"Target\"] = df[\"Target\"].replace({2:1})\n",
    "df[\"Target\"] = df[\"Target\"].replace({3:2})\n",
    "\n",
    "categorical_features = ['A', 'B', 'C', 'D', 'E','AD', 'DE', 'LD', 'FS', 'SUSP', 'CLASS'] ###\n",
    "continuous_features = list(OrderedSet(df.columns.to_list()) - OrderedSet([\"Target\"]) - OrderedSet(categorical_features))\n",
    "\n",
    "### fill NA\n",
    "for c in df.columns[df.isnull().any(axis=0)]:\n",
    "    if c in continuous_features:\n",
    "        df[c].fillna(df[c].mean(), inplace=True)\n",
    "    else:\n",
    "        df[c].fillna(df[c].mode()[0], inplace=True)\n",
    "\n",
    "def _clip_outliers(_df):\n",
    "    _df.loc[_df[\"FM.1\"]>0.00139*15,\"FM.1\"] = 0.00139*15\n",
    "_clip_outliers(df)\n",
    "\n",
    "train_fraction = 0.8 ###\n",
    "\n",
    "def get_data(seed):\n",
    "    df_train, df_test = shuffle_split_data(df, train_fraction, seed=seed)\n",
    "    \n",
    "    for feature in df_train.columns:\n",
    "        if feature in (categorical_features+[\"Target\"]):\n",
    "            continue\n",
    "        else:\n",
    "            lower = np.percentile(df_train[feature], 2)\n",
    "            upper = np.percentile(df_train[feature], 95 if feature in [\"FM.1\", \"ALTV\"] else 98)\n",
    "\n",
    "        df_train.loc[df_train[feature]<lower, feature] = lower\n",
    "        df_train.loc[df_train[feature]>upper, feature] = upper\n",
    "        df_test.loc[df_test[feature]<lower, feature] = lower\n",
    "        df_test.loc[df_test[feature]>upper, feature] = upper\n",
    "    \n",
    "    scaler_list = [MinMaxScaler(clip=True), MinMaxScaler(clip=True)]\n",
    "    feature_list = [continuous_features, categorical_features]\n",
    "    df_train_scaled, df_test_scaled = scale_features(df_train, df_test, feature_list, scaler_list)\n",
    "    return df_train_scaled, df_test_scaled, continuous_features, categorical_features\n",
    "\n",
    "_helper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82818483",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'CreditFraud'\n",
    "\n",
    "# source: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\n",
    "datapath = 'data_raw/CreditFraud/creditcard.csv'\n",
    "\n",
    "train_fraction = 0.75 ###\n",
    "\n",
    "def get_data(seed):\n",
    "    df = pd.read_csv(datapath)\n",
    "    fraud = df[df['Class']==1]\n",
    "    non_fraud = df[df['Class']==0].sample(2*len(fraud), random_state=seed)\n",
    "    df = non_fraud.append(fraud).reset_index(drop=True)\n",
    "    \n",
    "    df.rename(columns={\"Class\":\"Target\"}, inplace=True)\n",
    "    \n",
    "    categorical_features = [] ###\n",
    "    continuous_features = list(OrderedSet(df.columns.to_list()) - OrderedSet([\"Target\"]) - OrderedSet(categorical_features))\n",
    "    \n",
    "    df_train, df_test = shuffle_split_data(df, train_fraction, seed=seed)\n",
    "    \n",
    "    for feature in df_train.columns:\n",
    "        if feature in (categorical_features+[\"Target\"]):\n",
    "            continue\n",
    "        else:\n",
    "            lower = np.percentile(df_train[feature], 2)\n",
    "            upper = np.percentile(df_train[feature], 95 if feature==\"Amount\" else 98)\n",
    "        \n",
    "        df_train.loc[df_train[feature]<lower, feature] = lower\n",
    "        df_train.loc[df_train[feature]>upper, feature] = upper\n",
    "        df_test.loc[df_test[feature]<lower, feature] = lower\n",
    "        df_test.loc[df_test[feature]>upper, feature] = upper\n",
    "    \n",
    "    scaler_list = [MinMaxScaler(clip=True), MinMaxScaler(clip=True)]\n",
    "    feature_list = [continuous_features, categorical_features]\n",
    "    df_train_scaled, df_test_scaled = scale_features(df_train, df_test, feature_list, scaler_list)\n",
    "    return df_train_scaled, df_test_scaled, continuous_features, categorical_features\n",
    "\n",
    "_helper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ba39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'HAR'\n",
    "\n",
    "# source: https://www.kaggle.com/datasets/uciml/human-activity-recognition-with-smartphones\n",
    "datapath_tr = 'data_raw/HAR/train.csv'\n",
    "datapath_te = 'data_raw/HAR/test.csv'\n",
    "df_tr = pd.read_csv(datapath_tr)\n",
    "df_te = pd.read_csv(datapath_te)\n",
    "df = pd.concat([df_tr, df_te], ignore_index=False, copy=False)\n",
    "num_train = len(df_tr)\n",
    "\n",
    "df = df.drop(\"subject\", axis=1)\n",
    "\n",
    "# assign the column name of the target feature as \"Target\"\n",
    "df.rename(columns={\"Activity\":\"Target\"}, inplace=True)\n",
    "\n",
    "# make sure the label ranges from 0 to (num_class-1)\n",
    "df[\"Target\"] = LabelEncoder().fit_transform(df[\"Target\"])\n",
    "\n",
    "def get_data(seed):\n",
    "    df_train = shuffle_data(df.iloc[:num_train,:], seed=seed)\n",
    "    df_test = shuffle_data(df.iloc[num_train:,:], seed=seed)\n",
    "    \n",
    "    # dim reduction\n",
    "    features = list(OrderedSet(df_train.columns.to_list()) - OrderedSet([\"Target\"]))\n",
    "    scaler_list = [StandardScaler()]\n",
    "    feature_list = [features]\n",
    "    df_train, df_test = scale_features(df_train, df_test, feature_list, scaler_list)\n",
    "\n",
    "    pca = PCA(n_components=0.9, random_state=seed)\n",
    "    df_train = pd.concat([pd.DataFrame(pca.fit_transform(df_train[features])), df_train[\"Target\"]], axis=1)\n",
    "    df_test = pd.concat([pd.DataFrame(pca.transform(df_test[features])), df_test[\"Target\"]], axis=1)\n",
    "    df_train.rename(columns=lambda c: 'col'+str(c) if isinstance(c, int) else c, inplace=True)\n",
    "    df_test.rename(columns=lambda c: 'col'+str(c) if isinstance(c, int) else c, inplace=True)\n",
    "    \n",
    "    for feature in df_train.columns:\n",
    "        if feature==\"Target\":\n",
    "            continue\n",
    "        elif feature=='col0':\n",
    "            lower = np.percentile(df_train[feature], 1)\n",
    "            upper = np.percentile(df_train[feature], 99)\n",
    "        else:\n",
    "            q1 = df_train[feature].quantile(0.25)\n",
    "            q3 = df_train[feature].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower = q1 - 1.5 * iqr\n",
    "            upper = q3 + 1.5 * iqr\n",
    "\n",
    "        df_train.loc[df_train[feature]<lower, feature] = lower\n",
    "        df_train.loc[df_train[feature]>upper, feature] = upper\n",
    "        df_test.loc[df_test[feature]<lower, feature] = lower\n",
    "        df_test.loc[df_test[feature]>upper, feature] = upper\n",
    "    \n",
    "    categorical_features = [] ###\n",
    "    continuous_features = list(OrderedSet(df_train.columns.to_list()) - OrderedSet([\"Target\"]) - OrderedSet(categorical_features))\n",
    "    \n",
    "    scaler_list = [MinMaxScaler(clip=True), MinMaxScaler(clip=True)]\n",
    "    feature_list = [continuous_features, categorical_features]\n",
    "    df_train_scaled, df_test_scaled = scale_features(df_train, df_test, feature_list, scaler_list)\n",
    "    return df_train_scaled, df_test_scaled, continuous_features, categorical_features\n",
    "\n",
    "_helper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Letter'\n",
    "\n",
    "# source: https://www.kaggle.com/datasets/nishan192/letterrecognition-using-svm\n",
    "datapath = 'data_raw/Letter/letter-recognition.csv'\n",
    "df = pd.read_csv(datapath)\n",
    "\n",
    "# assign the column name of the target feature as \"Target\"\n",
    "df.rename(columns={\"letter\":\"Target\"}, inplace=True)\n",
    "\n",
    "# make sure the label ranges from 0 to (num_class-1)\n",
    "df[\"Target\"] = LabelEncoder().fit_transform(df[\"Target\"])\n",
    "\n",
    "categorical_features = [] ###\n",
    "continuous_features = list(OrderedSet(df.columns.to_list()) - OrderedSet([\"Target\"]) - OrderedSet(categorical_features))\n",
    "\n",
    "train_fraction = 0.75 ###\n",
    "\n",
    "def get_data(seed):\n",
    "    df_train, df_test = shuffle_split_data(df, train_fraction, seed=seed)\n",
    "    \n",
    "    for feature in continuous_features:\n",
    "        lower = np.percentile(df_train[feature], 1)\n",
    "        upper = np.percentile(df_train[feature], 99)\n",
    "\n",
    "        df_train.loc[df_train[feature]<lower, feature] = lower\n",
    "        df_train.loc[df_train[feature]>upper, feature] = upper\n",
    "        df_test.loc[df_test[feature]<lower, feature] = lower\n",
    "        df_test.loc[df_test[feature]>upper, feature] = upper\n",
    "    \n",
    "    scaler_list = [MinMaxScaler(clip=True), MinMaxScaler(clip=True)]\n",
    "    feature_list = [continuous_features, categorical_features]\n",
    "    df_train_scaled, df_test_scaled = scale_features(df_train, df_test, feature_list, scaler_list)\n",
    "    return df_train_scaled, df_test_scaled, continuous_features, categorical_features\n",
    "\n",
    "_helper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9453dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Mushroom'\n",
    "\n",
    "# source: https://www.kaggle.com/datasets/uciml/mushroom-classification\n",
    "datapath = 'data_raw/Mushroom/mushrooms.csv'\n",
    "df = pd.read_csv(datapath)\n",
    "\n",
    "df.rename(columns={\"class\":\"Target\"}, inplace=True)\n",
    "df[\"Target\"] = df[\"Target\"].replace({'e':0, 'p':1})\n",
    "\n",
    "df[\"cap-shape\"] = df[\"cap-shape\"].replace({'b':'other', 'c':'other', 's':'other'})\n",
    "df[\"cap-surface\"] = df[\"cap-surface\"].replace({'f':'other', 'g':'other'})\n",
    "df[\"cap-color\"] = df[\"cap-color\"].replace({'b':'other', 'c':'other', 'p':'other', 'r':'other', 'u':'other'})\n",
    "df[\"odor\"] = df[\"odor\"].replace({'c':'other', 'm':'other'})\n",
    "df[\"gill-color\"] = df[\"gill-color\"].replace({'e':'other', 'o':'other', 'r':'other', 'y':'other'})\n",
    "df[\"stalk-root\"] = df[\"stalk-root\"].replace({'c':'other', 'r':'other'})\n",
    "df[\"stalk-surface-above-ring\"] = df[\"stalk-surface-above-ring\"].replace({'f':'other', 'y':'other'})\n",
    "df[\"stalk-color-above-ring\"] = df[\"stalk-color-above-ring\"].replace({'c':'other', 'e':'other', 'o':'other', 'y':'other'})\n",
    "df[\"stalk-color-below-ring\"] = df[\"stalk-color-below-ring\"].replace({'c':'other', 'e':'other', 'o':'other', 'y':'other'})\n",
    "df[\"veil-color\"] = df[\"veil-color\"].replace({'n':'other', 'o':'other', 'y':'other'})\n",
    "df[\"ring-number\"] = df[\"ring-number\"].replace({'n':'other', 't':'other'})\n",
    "df[\"ring-type\"] = df[\"ring-type\"].replace({'f':'other', 'l':'other', 'n':'other'})\n",
    "df[\"spore-print-color\"] = df[\"spore-print-color\"].replace({'b':'other', 'o':'other', 'r':'other', 'u':'other', 'y':'other'})\n",
    "\n",
    "df = df.drop([\"veil-type\"], axis=1)\n",
    "\n",
    "to_dummy = []\n",
    "to_le = []\n",
    "for feature in list(OrderedSet(df.columns.to_list()) - OrderedSet([\"Target\"])):\n",
    "    if len(np.unique(df[feature]))>2:\n",
    "        to_dummy.append(feature)\n",
    "    else:\n",
    "        to_le.append(feature)\n",
    "df = pd.get_dummies(df, prefix=to_dummy, columns=to_dummy, drop_first=True)\n",
    "le = LabelEncoder()\n",
    "df[to_le] = df[to_le].apply(lambda col: le.fit_transform(col))\n",
    "\n",
    "df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "continuous_features = [] ###\n",
    "categorical_features = list(OrderedSet(df.columns.to_list()) - OrderedSet([\"Target\"]) - OrderedSet(continuous_features))\n",
    "\n",
    "train_fraction = 0.75 ###\n",
    "\n",
    "def get_data(seed):\n",
    "    df_train, df_test = shuffle_split_data(df, train_fraction, seed=seed)\n",
    "    \n",
    "    scaler_list = [MinMaxScaler(clip=True), MinMaxScaler(clip=True)]\n",
    "    feature_list = [continuous_features, categorical_features]\n",
    "    df_train_scaled, df_test_scaled = scale_features(df_train, df_test, feature_list, scaler_list)\n",
    "    return df_train_scaled, df_test_scaled, continuous_features, categorical_features\n",
    "\n",
    "_helper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ace999",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'SatIm'\n",
    "\n",
    "# source: https://www.kaggle.com/datasets/markjibrilmononutu/statlog-landsat-satellite-data-set\n",
    "datapath_tr = 'data_raw/SatIm/sat_train.csv'\n",
    "datapath_te = 'data_raw/SatIm/sat_test.csv'\n",
    "df_tr = pd.read_csv(datapath_tr)\n",
    "df_te = pd.read_csv(datapath_te)\n",
    "df = pd.concat([df_tr, df_te], ignore_index=False, copy=False)\n",
    "num_train = len(df_tr)\n",
    "\n",
    "# assign the column name of the target feature as \"Target\"\n",
    "df.rename(columns={\"label\":\"Target\"}, inplace=True)\n",
    "\n",
    "# make sure the label ranges from 0 to (num_class-1)\n",
    "df[\"Target\"] = LabelEncoder().fit_transform(df[\"Target\"])\n",
    "\n",
    "continuous_features = list(OrderedSet(df.columns.to_list()) - OrderedSet([\"Target\"])) ###\n",
    "categorical_features = list(OrderedSet(df.columns.to_list()) - OrderedSet([\"Target\"]) - OrderedSet(continuous_features))\n",
    "\n",
    "def get_data(seed):\n",
    "    df_train = shuffle_data(df.iloc[:num_train,:], seed=seed)\n",
    "    df_test = shuffle_data(df.iloc[num_train:,:], seed=seed)\n",
    "    \n",
    "    for feature in continuous_features:\n",
    "        lower = np.percentile(df_train[feature], 1)\n",
    "        upper = np.percentile(df_train[feature], 99)\n",
    "\n",
    "        df_train.loc[df_train[feature]<lower, feature] = lower\n",
    "        df_train.loc[df_train[feature]>upper, feature] = upper\n",
    "        df_test.loc[df_test[feature]<lower, feature] = lower\n",
    "        df_test.loc[df_test[feature]>upper, feature] = upper\n",
    "    \n",
    "    scaler_list = [MinMaxScaler(clip=True), MinMaxScaler(clip=True)]\n",
    "    feature_list = [continuous_features, categorical_features]\n",
    "    df_train_scaled, df_test_scaled = scale_features(df_train, df_test, feature_list, scaler_list)\n",
    "    return df_train_scaled, df_test_scaled, continuous_features, categorical_features\n",
    "\n",
    "_helper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'SenDrive'\n",
    "\n",
    "# source: https://archive.ics.uci.edu/ml/datasets/dataset+for+sensorless+drive+diagnosis\n",
    "datapath = 'data_raw/SenDrive/Sensorless_drive_diagnosis.txt'\n",
    "df = pd.read_csv(datapath, sep=\" \", header=None)\n",
    "\n",
    "df.rename(columns=lambda c: 'col'+str(c), inplace=True)\n",
    "\n",
    "# assign the column name of the target feature as \"Target\"\n",
    "df.rename(columns={'col48':\"Target\"}, inplace=True)\n",
    "\n",
    "# make sure the label ranges from 0 to (num_class-1)\n",
    "df[\"Target\"] = LabelEncoder().fit_transform(df[\"Target\"])\n",
    "\n",
    "categorical_features = [] ###\n",
    "continuous_features = list(OrderedSet(df.columns.to_list()) - OrderedSet([\"Target\"]) - OrderedSet(categorical_features))\n",
    "\n",
    "train_fraction = 0.75 ###\n",
    "\n",
    "def get_data(seed):\n",
    "    df_train, df_test = shuffle_split_data(df, train_fraction, seed=seed)\n",
    "    \n",
    "    for feature in continuous_features:\n",
    "        lower = np.percentile(df_train[feature], 2)\n",
    "        upper = np.percentile(df_train[feature], 98)\n",
    "        \n",
    "        df_train.loc[df_train[feature]<lower, feature] = lower\n",
    "        df_train.loc[df_train[feature]>upper, feature] = upper\n",
    "        df_test.loc[df_test[feature]<lower, feature] = lower\n",
    "        df_test.loc[df_test[feature]>upper, feature] = upper\n",
    "    \n",
    "    scaler_list = [MinMaxScaler(clip=True), MinMaxScaler(clip=True)]\n",
    "    feature_list = [continuous_features, categorical_features]\n",
    "    df_train_scaled, df_test_scaled = scale_features(df_train, df_test, feature_list, scaler_list)\n",
    "    return df_train_scaled, df_test_scaled, continuous_features, categorical_features\n",
    "\n",
    "_helper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736cb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
